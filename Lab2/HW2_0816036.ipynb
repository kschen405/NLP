{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "\n",
    "\n",
    "# 0. all words -(nltk)-> all word_tokenize\n",
    "# 1. all word_tokenize -(nltk)-> remove stop words\n",
    "# 2. words -(TextVectorization)-> word_index\n",
    "# 3. words -(glove)-> word_embedding\n",
    "# 4. word_index : word_embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "\n",
    "# train_path = 'data/train_HW2dataset.csv'\n",
    "# val_path = 'data/dev_HW2dataset.csv'\n",
    "# test_path = 'data/test_HW2dataset.csv'\n",
    "\n",
    "# df = pd.read_csv(train_path)\n",
    "# dev_df = pd.read_csv(val_path)\n",
    "# test_df = pd.read_csv(test_path)\n",
    "\n",
    "# x_train = df['Utterance']\n",
    "# print(type(contractions.fix(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Did you really?'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"Did you really?\"\n",
    "\"\".join(s for s in sample if s.isalpha() or s in [\"!\", \"?\", \".\", \"'\", \" \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "# aug = naw.WordEmbsAug(model_type='glove', model_path='model\\_glove.840B.300d\\glove.840B.300d.txt',action=\"substitute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contraction(x_train, y_train, duplicate_ratios=None):\n",
    "    print(\"in expand\")\n",
    "    if duplicate_ratios is not None:\n",
    "        for index, sample in enumerate(x_train):\n",
    "            augmented_sample = aug.augment(sample)\n",
    "            # print(len(x_train))\n",
    "            # print(x_train.tail(1))\n",
    "            tmp_df = pd.DataFrame(augmented_sample)\n",
    "            x_train = pd.concat([x_train, tmp_df], axis=0)\n",
    "            y_train.append(y_train[index])\n",
    "\n",
    "        x_train = x_train.reset_index().drop([\"index\"], axis=1)[0].values.tolist()\n",
    "    output = []\n",
    "    for i, sample in enumerate(x_train):\n",
    "        sample = contractions.fix(sample).lower().replace(\"—\", \" \").replace(\"-\", \" \").replace(\"_\", \" \")\n",
    "        output.append(\"\".join(s for s in sample if s.isalpha() or s in [\"!\", \"?\", \".\", \"'\", \" \"]))\n",
    "        # for j, s in enumerate(sample):\n",
    "        #     if s.isalpha() or s in [\"!\", \"?\", \".\", \"'\", \" \"]:\n",
    "        #         continue\n",
    "        #     else:\n",
    "        #         print(\"string\", sample, len(sample))\n",
    "        #         tmp = list(sample)\n",
    "        #         print(\"list\", tmp, len(tmp))\n",
    "        #         print(\"j = \", j)\n",
    "        #         tmp[j] = \" \"\n",
    "        #         sample = \"\".join(tmp)\n",
    "    # x_train = x_train.str.lower().str.replace(\"-\", \" \").str.replace(\"_\", \" \").str.replace(\"—\", \" \")\n",
    "    # x_train = x_train.str.replace(r'[^\\w\\s]+', '').str.replace('\\d+', '')\n",
    "    # print(x_train)\n",
    "    print(\"end expand\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = 'data/train_HW2dataset.csv'\n",
    "# val_path = 'data/dev_HW2dataset.csv'\n",
    "# test_path = 'data/test_HW2dataset.csv'\n",
    "\n",
    "# df = pd.read_csv(train_path)\n",
    "\n",
    "# x_train = df['Utterance']\n",
    "# y_train = df['Emotion'].values.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def read_data(train_path, val_path, test_path):\n",
    "    df = pd.read_csv(train_path)\n",
    "    dev_df = pd.read_csv(val_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    y_train = df['Emotion'].values.tolist()\n",
    "    y_valid = dev_df['Emotion'].values.tolist()\n",
    "\n",
    "    # compute duplicate ratio\n",
    "    emotion_label = {\"neutral\": 0, \"anger\": 1, \"joy\": 2, \"surprise\": 3, \"sadness\": 4, \"disgust\": 5, \"fear\":6}\n",
    "    duplicate_ratios = {}\n",
    "    count = Counter()\n",
    "    for emotion in [y_train, y_valid]:\n",
    "        count.update(emotion)\n",
    "    \n",
    "    for emotion in count:\n",
    "        max_key = max(count, key=count.get)\n",
    "        ratio = count[max_key] // count[emotion]\n",
    "        duplicate_ratios[ emotion_label[emotion] ] = ratio\n",
    "    print(count)\n",
    "\n",
    "    # pre-processing & duplicate\n",
    "    x_train = expand_contraction(df['Utterance'], y_train, duplicate_ratios)\n",
    "\n",
    "    x_valid = expand_contraction(dev_df['Utterance'].values.tolist(), y_valid, None)\n",
    "    x_test = expand_contraction(test_df['Utterance'].values.tolist(), None, None)\n",
    "    print(\"read data, ok\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return duplicate_ratios, x_train, y_train, x_valid, y_valid, x_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = 'data/train_HW2dataset.csv'\n",
    "# val_path = 'data/dev_HW2dataset.csv'\n",
    "# test_path = 'data/test_HW2dataset.csv'\n",
    "\n",
    "# duplicate_ratios, x_train, y_train, x_valid, y_valid, x_test = read_data(train_path, val_path, test_path)\n",
    "# print(duplicate_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_to_label(y):\n",
    "    labels = np.zeros((len(y), 7))\n",
    "    emotion_label = {\"neutral\": 0, \"anger\": 1, \"joy\": 2, \"surprise\": 3, \"sadness\": 4, \"disgust\": 5, \"fear\":6}\n",
    "    for i in range(len(y)):\n",
    "        labels[i][ emotion_label[y[i]]] = 1\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = \"hello?! how, are-you54_3(^&$\"\n",
    "\n",
    "# sample = sample.replace(\"_\", \" \")\n",
    "# sample = sample.replace(\"-\", \" \")\n",
    "# sample = sample.replace(\"—\", \" \")\n",
    "\n",
    "# for s in sample:\n",
    "#     if s.isalnum() or s in [\"!\", \"?\", \".\", \"'\", \" \"]:\n",
    "#         continue\n",
    "#     elif s in [\"-\", \"_\", \"—\"]:\n",
    "#         s = \" \"\n",
    "#     else:\n",
    "#         s = \"\"\n",
    "# # sample = ''.join(s for s in sample if  s.isalnum() or (s in [\"!\", \"?\", \"'\", \" \"]) )\n",
    "\n",
    "# print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# stop_words.difference_update([\"not\", \"no\", \"why\", \"how\"])\n",
    "print(\"not\" in stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug = naw.WordEmbsAug(\n",
    "#     model_type='glove', model_path='model\\_glove.840B.300d\\glove.840B.300d.txt',\n",
    "#     action=\"substitute\")\n",
    "# augmented_text = aug.augment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def tokenized_remove_stopwords(samples, labels=None, duplicate_ratios=None):\n",
    "    # neutral -> 0\n",
    "    if labels is not None:\n",
    "        labels = emotion_to_label(labels)\n",
    "\n",
    "\n",
    "    \n",
    "    # stop_words = set(stopwords.words('english'))\n",
    "    # stop_words.difference_update({\"not\", \"no\", \"why\", \"how\"})\n",
    "    valid_words = set(nltk.corpus.words.words())\n",
    "    valid_words.update([\"!\", \"?\", \".\", \"'\"])\n",
    "    \n",
    "    tokenized_samples = []\n",
    "    duplicate_index = []\n",
    "    max_cnt = -1\n",
    "    for i, sample in enumerate(samples):\n",
    "        cnt = 0\n",
    "        # for i, s in enumerate(sample):\n",
    "        #     if s.isalnum() or s in [\"!\", \"?\", \".\", \"'\", \" \"]:\n",
    "        #         continue\n",
    "        #     elif s in [\"-\", \"_\", \"—\"]:\n",
    "        #         sample = \" \"\n",
    "        #     else:\n",
    "        #         s = \"\"\n",
    "\n",
    "        word_tokens = word_tokenize(sample)\n",
    "        \n",
    "        clean_sample = \"\"\n",
    "        for word in word_tokens:\n",
    "            # if (word.lower() not in stop_words): # (word.lower() in valid_words) : # and \n",
    "            clean_sample = clean_sample + \" \" + word\n",
    "            cnt += 1\n",
    "        \n",
    "        # train, valid mode\n",
    "        if duplicate_ratios is not None and labels[i][0] != 0:\n",
    "            duplicate_times = duplicate_ratios[ np.argmax(labels[i]) ]\n",
    "            for _ in range(duplicate_times):\n",
    "                duplicate_index.append(i)\n",
    "        # if i == 4:\n",
    "        #     print(clean_sample)\n",
    "        tokenized_samples.append(clean_sample)\n",
    "        max_cnt = max(max_cnt, cnt)\n",
    "    print(\"max cnt = \", max_cnt)\n",
    "    print(\"tokenized_remove_stopwords, ok\")\n",
    "    if duplicate_ratios is not None:\n",
    "        for d_index in duplicate_index:\n",
    "            augmented_text = aug.augment(tokenized_samples[d_index])\n",
    "            tokenized_samples.append(augmented_text)\n",
    "            labels = np.concatenate([labels, np.expand_dims(labels[d_index], axis=0)], axis=0)\n",
    "\n",
    "    # count = Counter(labels)\n",
    "    # print(count)\n",
    "    return tokenized_samples, labels\n",
    "\n",
    "# train_path = 'data/train_HW2dataset.csv'\n",
    "# val_path = 'data/dev_HW2dataset.csv'\n",
    "# test_path = 'data/test_HW2dataset.csv'\n",
    "\n",
    "# duplicate_ratios, x_train, y_train, x_valid, y_valid, x_test = read_data(train_path, val_path, test_path)\n",
    "# tokenized_train, label_train = tokenized_remove_stopwords(x_train[1000:], None, duplicate_ratios=None)\n",
    "# print(tokenized_train[4])\n",
    "\n",
    "# t_samples = tokenized_remove_stopwords([\"I jkdgh not no see happy ?! .\"])\n",
    "# print(t_samples)\n",
    "# print(tokenized_samples[:2])\n",
    "# tmp = max([ len(t) for t in tokenized_samples])\n",
    "# print(\"max sample word lenth = \", tmp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TextVectorization\n",
    "\n",
    "def word_to_index(tokenized_samples:list, SAMPLE_LENGTH=60):\n",
    "    vectorizer = TextVectorization(output_sequence_length=SAMPLE_LENGTH)\n",
    "    text_ds = tf.data.Dataset.from_tensor_slices(tokenized_samples).batch(1024)\n",
    "    vectorizer.adapt(text_ds)\n",
    "    print(\"word_to_index, ok\")\n",
    "    return vectorizer\n",
    "\n",
    "# vectorizer = word_to_index(tokenized_samples)\n",
    "# word_index_example = vectorizer(tokenized_samples[1]).numpy()\n",
    "# print(word_index_example)\n",
    "# print(vectorizer.get_vocabulary()[166])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding_dict(glove_size=300):\n",
    "    word_embedding_dict = {}\n",
    "\n",
    "    with open(f\"model\\glove.840B.300d.txt\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            word, embeddings = line.split(maxsplit=1)\n",
    "            embeddings = np.fromstring(embeddings, \"f\", sep=\" \")\n",
    "            \n",
    "            word_embedding_dict[word] = embeddings\n",
    "\n",
    "    print(\"get_word_embedding_dict, ok\")\n",
    "    print(\"Found %s word vectors.\" % len(word_embedding_dict))\n",
    "    return word_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_embedding_matrix(vectorizer, word_embedding_dict):\n",
    "    all_sample_words = vectorizer.get_vocabulary()\n",
    "    word_index_dict = dict(zip(all_sample_words, range(len(all_sample_words))))\n",
    "    index_embedding_matrix = np.zeros((len(all_sample_words), 300) )\n",
    "    hit = 0\n",
    "    miss = 0\n",
    "    for word, index in word_index_dict.items():\n",
    "        embedding = word_embedding_dict.get(word)\n",
    "        if embedding is not None and embedding.shape != (0,):\n",
    "            # print(f\"hit: {word}\", embedding.shape)\n",
    "            \n",
    "            index_embedding_matrix[index] = embedding\n",
    "            hit += 1\n",
    "        else:\n",
    "            miss += 1\n",
    "            print(f\"miss: {word}\")\n",
    "    print(f\"hit = {hit}, miss = {miss}\")\n",
    "    print(\"get_index_embedding_matrix, ok\")\n",
    "    return all_sample_words, index_embedding_matrix\n",
    "    \n",
    "# index_embedding_matrix = get_index_embedding_matrix(all_sample_words, word_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dropout, LSTM, Dense, Bidirectional, Layer, Flatten\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "def train(all_sample_words, embedding_matrix, x_train, y_train, x_valid, y_valid, SAMPLE_LENGTH):\n",
    "    \n",
    "    class Metrics(tf.keras.callbacks.Callback):\n",
    "        def __init__(self, valid_data):\n",
    "            super(Metrics, self).__init__()\n",
    "            self.validation_data = valid_data\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            logs = logs or {}\n",
    "            val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
    "            val_targ = self.validation_data[1]\n",
    "            if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
    "                val_targ = np.argmax(val_targ, -1)\n",
    "\n",
    "            _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
    "            _val_recall = recall_score(val_targ, val_predict, average='macro')\n",
    "            _val_precision = precision_score(val_targ, val_predict, average='macro')\n",
    "\n",
    "            logs['val_f1'] = _val_f1\n",
    "            # logs['val_recall'] = _val_recall\n",
    "            # logs['val_precision'] = _val_precision\n",
    "            # print(\" — val_f1: %f \" % (_val_f1))\n",
    "            return\n",
    "    \n",
    "    \n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=len(all_sample_words),\n",
    "        output_dim=300,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "        input_length=SAMPLE_LENGTH,\n",
    "        trainable=False,\n",
    "    )\n",
    "\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Bidirectional(LSTM(16, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    # model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "    # model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    # model.add(LSTM(16, dropout=0.2, recurrent_dropout=0.2))\n",
    "    # model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    # model.add(Flatten())\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    # model.summary()\n",
    "    print(np.array(x_train).shape)\n",
    "    print(np.array(y_train).shape)\n",
    "    print(np.array(x_valid).shape)\n",
    "    print(np.array(y_valid).shape)\n",
    "\n",
    "    ck_callback = tf.keras.callbacks.ModelCheckpoint('./checkpoints/new_balance_{epoch:02d}.pth', verbose=2, save_freq=\"epoch\")\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", profile_batch=0)\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_valid = np.array(x_valid)\n",
    "    y_valid = np.array(y_valid)\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=200, \n",
    "                validation_data=(x_valid, y_valid),\n",
    "                callbacks=[Metrics(valid_data=(x_valid, y_valid)), ck_callback, tb_callback])\n",
    "    # model.fit(np.array(x_train), np.array(y_train), batch_size=128, epochs=20, validation_data=(np.array(x_valid), np.array(y_valid)))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_word_embedding_dict, ok\n",
      "Found 2195885 word vectors.\n"
     ]
    }
   ],
   "source": [
    "word_embedding_dict = get_word_embedding_dict(glove_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'neutral': 6560, 'joy': 2526, 'anger': 1708, 'surprise': 1700, 'sadness': 1021, 'disgust': 395, 'fear': 392})\n",
      "in expand\n",
      "end expand\n",
      "in expand\n",
      "end expand\n",
      "in expand\n",
      "end expand\n",
      "read data, ok\n",
      "max cnt =  79\n",
      "tokenized_remove_stopwords, ok\n",
      "max cnt =  42\n",
      "tokenized_remove_stopwords, ok\n",
      "max cnt =  50\n",
      "tokenized_remove_stopwords, ok\n",
      "word_to_index, ok\n"
     ]
    }
   ],
   "source": [
    "train_path = 'data/train_HW2dataset.csv'\n",
    "val_path = 'data/dev_HW2dataset.csv'\n",
    "test_path = 'data/test_HW2dataset.csv'\n",
    "\n",
    "duplicate_ratios, x_train, y_train, x_valid, y_valid, x_test = read_data(train_path, val_path, test_path)\n",
    "tokenized_train, label_train = tokenized_remove_stopwords(x_train, y_train, duplicate_ratios=None)\n",
    "tokenized_val, label_val = tokenized_remove_stopwords(x_valid, y_valid, None)\n",
    "tokenized_test, _ = tokenized_remove_stopwords(x_test, None, None)\n",
    "tokenized_samples = tokenized_train + tokenized_val\n",
    "\n",
    "SAMPLE_LENGTH = 85\n",
    "vectorizer = word_to_index(tokenized_samples, SAMPLE_LENGTH=SAMPLE_LENGTH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss: \n",
      "miss: [UNK]\n",
      "miss: to\n",
      "miss: is\n",
      "miss: in\n",
      "miss: on\n",
      "miss: at\n",
      "miss: or\n",
      "miss: by\n",
      "miss: iodin\n",
      "miss: pheebs\n",
      "miss: boutros\n",
      "miss: tayloe\n",
      "miss: heldi\n",
      "miss: griscom\n",
      "miss: sidesplitter\n",
      "miss: sauti\n",
      "miss: treeger\n",
      "miss: thquirt\n",
      "miss: rosselini\n",
      "miss: secern\n",
      "miss: sayornis\n",
      "miss: rosss\n",
      "miss: remoray\n",
      "miss: phoebs\n",
      "miss: oooooooooooooohhhhhhhhhhh\n",
      "miss: nngghhh\n",
      "miss: gerston\n",
      "miss: mebibyte\n",
      "miss: zelner\n",
      "miss: willick\n",
      "miss: siadic\n",
      "miss: severalise\n",
      "miss: scrud\n",
      "miss: magioni\n",
      "miss: holierthanthou\n",
      "miss: goodacre\n",
      "miss: bapstein\n",
      "miss: ysee\n",
      "miss: viosterol\n",
      "miss: secernate\n",
      "miss: whoooaa\n",
      "miss: waxine\n",
      "miss: velula\n",
      "miss: testosteroney\n",
      "miss: tedlock\n",
      "miss: suity\n",
      "miss: squatternut\n",
      "miss: snuffalopagus\n",
      "miss: schemp\n",
      "miss: rdtor\n",
      "miss: ramoray\n",
      "miss: phobo\n",
      "miss: phewbedo\n",
      "miss: phaybobo\n",
      "miss: nokululu\n",
      "miss: mwwwooooo\n",
      "miss: monana\n",
      "miss: mississ\n",
      "miss: mashuga\n",
      "miss: markson\n",
      "miss: maaaaadd\n",
      "miss: johnos\n",
      "miss: janines\n",
      "miss: hurely\n",
      "miss: hhiii\n",
      "miss: gepeto\n",
      "miss: gellers\n",
      "miss: dubbies\n",
      "miss: cupert\n",
      "miss: cmere\n",
      "miss: cinderelly\n",
      "miss: churo\n",
      "miss: cheshhh\n",
      "miss: chatracus\n",
      "miss: buash\n",
      "miss: blurtin\n",
      "miss: blobbies\n",
      "miss: blarrglarrghh\n",
      "miss: artelle\n",
      "miss: youss\n",
      "miss: severalize\n",
      "miss: zelners\n",
      "miss: yentel\n",
      "miss: wxrk\n",
      "miss: woolery\n",
      "miss: womba\n",
      "miss: withgirls\n",
      "miss: westburg\n",
      "miss: wellsounds\n",
      "miss: wellso\n",
      "miss: weeeell\n",
      "miss: unplayful\n",
      "miss: unmarriable\n",
      "miss: twoscore\n",
      "miss: tuschy\n",
      "miss: trrrribbiani\n",
      "miss: trorro\n",
      "miss: tolouse\n",
      "miss: toiba\n",
      "miss: tibidaybo\n",
      "miss: thesell\n",
      "miss: tayyiba\n",
      "miss: sydenstricker\n",
      "miss: sulkov\n",
      "miss: spleeeen\n",
      "miss: spackel\n",
      "miss: spacecamp\n",
      "miss: smiledon\n",
      "miss: sleeperson\n",
      "miss: shmair\n",
      "miss: shirvel\n",
      "miss: seeeeen\n",
      "miss: schmoon\n",
      "miss: sabbatum\n",
      "miss: realilized\n",
      "miss: ramorays\n",
      "miss: progressionist\n",
      "miss: philange\n",
      "miss: pfieffer\n",
      "miss: perspirer\n",
      "miss: overjealous\n",
      "miss: oldé\n",
      "miss: ofsexy\n",
      "miss: newold\n",
      "miss: neurolic\n",
      "miss: nestley\n",
      "miss: nesele\n",
      "miss: monnnnn\n",
      "miss: medeio\n",
      "miss: mcpretty\n",
      "miss: mcnailshisstudents\n",
      "miss: longifolium\n",
      "miss: lisettie\n",
      "miss: lafite\n",
      "miss: lacys\n",
      "miss: kostelick\n",
      "miss: kleinmans\n",
      "miss: justthrow\n",
      "miss: joshuas\n",
      "miss: ithiel\n",
      "miss: issacs\n",
      "miss: isoh\n",
      "miss: howhow\n",
      "miss: hooohhh\n",
      "miss: gstephanopoulos\n",
      "miss: gobb\n",
      "miss: giiiiiiift\n",
      "miss: franzblau\n",
      "miss: flennin\n",
      "miss: fabutec\n",
      "miss: ezels\n",
      "miss: ewwuck\n",
      "miss: enhh\n",
      "miss: embryossss\n",
      "miss: dwha\n",
      "miss: draddle\n",
      "miss: disgustingtons\n",
      "miss: devane\n",
      "miss: delvecchio\n",
      "miss: crumbies\n",
      "miss: cowlicky\n",
      "miss: costalano\n",
      "miss: contact\n",
      "miss: concenter\n",
      "miss: commove\n",
      "miss: christmastide\n",
      "miss: chickeeeen\n",
      "miss: cheeseflower\n",
      "miss: calophyllum\n",
      "miss: boredddd\n",
      "miss: blargon\n",
      "miss: beaudalire\n",
      "miss: bazida\n",
      "miss: argentinaaaa\n",
      "miss: anglesea\n",
      "miss: allwe\n",
      "miss: ahget\n",
      "miss: ythink\n",
      "miss: yoursis\n",
      "miss: youarenot\n",
      "miss: yhave\n",
      "miss: yever\n",
      "miss: werewe\n",
      "miss: welllet\n",
      "miss: wellfall\n",
      "miss: welldid\n",
      "miss: venthole\n",
      "miss: valentes\n",
      "miss: uranologist\n",
      "miss: unconstipated\n",
      "miss: ummwe\n",
      "miss: ummohwho\n",
      "miss: ummhere\n",
      "miss: umbut\n",
      "miss: uhwe\n",
      "miss: uhhow\n",
      "miss: uhboy\n",
      "miss: trygve\n",
      "miss: thathot\n",
      "miss: tchad\n",
      "miss: talocruralis\n",
      "miss: symmetricalness\n",
      "miss: swob\n",
      "miss: streisands\n",
      "miss: stereophony\n",
      "miss: spermatozoan\n",
      "miss: sonice\n",
      "miss: somewherefun\n",
      "miss: sohere\n",
      "miss: sodomist\n",
      "miss: slicesix\n",
      "miss: sectionalization\n",
      "miss: schoolmaam\n",
      "miss: rosten\n",
      "miss: rossgeller\n",
      "miss: reallyvery\n",
      "miss: rattraps\n",
      "miss: rarify\n",
      "miss: quiescency\n",
      "miss: quetch\n",
      "miss: porsching\n",
      "miss: polemonium\n",
      "miss: plagiariser\n",
      "miss: penthat\n",
      "miss: parentteacher\n",
      "miss: palpebra\n",
      "miss: osculator\n",
      "miss: orpoison\n",
      "miss: omally\n",
      "miss: ohwaityou\n",
      "miss: officerpretty\n",
      "miss: octonary\n",
      "miss: nipponese\n",
      "miss: netkeeper\n",
      "miss: muhawa\n",
      "miss: mellisonant\n",
      "miss: mcmath\n",
      "miss: marlais\n",
      "miss: mamilla\n",
      "miss: lunchby\n",
      "miss: lodowic\n",
      "miss: littleerotica\n",
      "miss: lauers\n",
      "miss: lallation\n",
      "miss: justtake\n",
      "miss: justcannot\n",
      "miss: janices\n",
      "miss: iskind\n",
      "miss: isdo\n",
      "miss: ilxxx\n",
      "miss: ilich\n",
      "miss: idrank\n",
      "miss: hemipteron\n",
      "miss: hebdomadary\n",
      "miss: halvden\n",
      "miss: gymtreat\n",
      "miss: greelys\n",
      "miss: grabgrab\n",
      "miss: goyou\n",
      "miss: gottheother\n",
      "miss: goodpill\n",
      "miss: godwhat\n",
      "miss: francein\n",
      "miss: fossilology\n",
      "miss: fleeceable\n",
      "miss: filmthat\n",
      "miss: fillpot\n",
      "miss: felicitousness\n",
      "miss: extolment\n",
      "miss: expressage\n",
      "miss: europewestern\n",
      "miss: erwins\n",
      "miss: eruct\n",
      "miss: englut\n",
      "miss: drumfish\n",
      "miss: dknow\n",
      "miss: diddlyshit\n",
      "miss: desexualise\n",
      "miss: depone\n",
      "miss: coriandrum\n",
      "miss: comatoseness\n",
      "miss: coldcock\n",
      "miss: chargeman\n",
      "miss: capelan\n",
      "miss: byvikings\n",
      "miss: bruntiae\n",
      "miss: bowmonts\n",
      "miss: bowmont\n",
      "miss: beigel\n",
      "miss: beerbohm\n",
      "miss: bartholomeu\n",
      "miss: ballock\n",
      "miss: apium\n",
      "miss: anathemise\n",
      "miss: amerind\n",
      "miss: allhallows\n",
      "miss: alessandros\n",
      "miss: agnize\n",
      "miss: agnise\n",
      "miss: adriennes\n",
      "miss: admirableness\n",
      "miss: aboutthere\n",
      "hit = 8667, miss = 303\n",
      "get_index_embedding_matrix, ok\n"
     ]
    }
   ],
   "source": [
    "all_sample_words, index_embedding_matrix = get_index_embedding_matrix(vectorizer, word_embedding_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(word_embedding_dict[\"email\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25680, 85)\n",
      "(25680, 7)\n",
      "(1462, 85)\n",
      "(1462, 7)\n",
      "Epoch 1/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 1: saving model to ./checkpoints\\new_balance_01.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_01.pth\\assets\n",
      "201/201 [==============================] - 62s 291ms/step - loss: 1.5984 - accuracy: 0.4511 - val_loss: 1.5925 - val_accuracy: 0.4104 - val_f1: 0.0831\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 2: saving model to ./checkpoints\\new_balance_02.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_02.pth\\assets\n",
      "201/201 [==============================] - 58s 288ms/step - loss: 1.4815 - accuracy: 0.4742 - val_loss: 1.4991 - val_accuracy: 0.4460 - val_f1: 0.1607\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 3: saving model to ./checkpoints\\new_balance_03.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_03.pth\\assets\n",
      "201/201 [==============================] - 58s 289ms/step - loss: 1.4396 - accuracy: 0.4890 - val_loss: 1.4756 - val_accuracy: 0.4432 - val_f1: 0.1525\n",
      "Epoch 4/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 4: saving model to ./checkpoints\\new_balance_04.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_04.pth\\assets\n",
      "201/201 [==============================] - 58s 290ms/step - loss: 1.4117 - accuracy: 0.4966 - val_loss: 1.4710 - val_accuracy: 0.4583 - val_f1: 0.1848\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 5: saving model to ./checkpoints\\new_balance_05.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_05.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.3906 - accuracy: 0.5018 - val_loss: 1.4705 - val_accuracy: 0.4508 - val_f1: 0.1711\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 6: saving model to ./checkpoints\\new_balance_06.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_06.pth\\assets\n",
      "201/201 [==============================] - 58s 291ms/step - loss: 1.3711 - accuracy: 0.5069 - val_loss: 1.4502 - val_accuracy: 0.4542 - val_f1: 0.1890\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 7: saving model to ./checkpoints\\new_balance_07.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_07.pth\\assets\n",
      "201/201 [==============================] - 58s 291ms/step - loss: 1.3532 - accuracy: 0.5139 - val_loss: 1.4799 - val_accuracy: 0.4569 - val_f1: 0.1899\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 8: saving model to ./checkpoints\\new_balance_08.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_08.pth\\assets\n",
      "201/201 [==============================] - 58s 291ms/step - loss: 1.3382 - accuracy: 0.5171 - val_loss: 1.4662 - val_accuracy: 0.4836 - val_f1: 0.2408\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 9: saving model to ./checkpoints\\new_balance_09.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_09.pth\\assets\n",
      "201/201 [==============================] - 58s 290ms/step - loss: 1.3308 - accuracy: 0.5194 - val_loss: 1.4736 - val_accuracy: 0.4651 - val_f1: 0.2213\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 10: saving model to ./checkpoints\\new_balance_10.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_10.pth\\assets\n",
      "201/201 [==============================] - 59s 293ms/step - loss: 1.3137 - accuracy: 0.5254 - val_loss: 1.4560 - val_accuracy: 0.4781 - val_f1: 0.2543\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 11: saving model to ./checkpoints\\new_balance_11.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_11.pth\\assets\n",
      "201/201 [==============================] - 58s 291ms/step - loss: 1.3015 - accuracy: 0.5299 - val_loss: 1.4664 - val_accuracy: 0.4726 - val_f1: 0.2357\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 12: saving model to ./checkpoints\\new_balance_12.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_12.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.2928 - accuracy: 0.5346 - val_loss: 1.4763 - val_accuracy: 0.4808 - val_f1: 0.2632\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 13: saving model to ./checkpoints\\new_balance_13.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_13.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.2866 - accuracy: 0.5376 - val_loss: 1.4553 - val_accuracy: 0.4856 - val_f1: 0.2795\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 14: saving model to ./checkpoints\\new_balance_14.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_14.pth\\assets\n",
      "201/201 [==============================] - 59s 294ms/step - loss: 1.2711 - accuracy: 0.5404 - val_loss: 1.4731 - val_accuracy: 0.4713 - val_f1: 0.2702\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 15: saving model to ./checkpoints\\new_balance_15.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_15.pth\\assets\n",
      "201/201 [==============================] - 58s 291ms/step - loss: 1.2568 - accuracy: 0.5468 - val_loss: 1.4592 - val_accuracy: 0.4679 - val_f1: 0.2855\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 16: saving model to ./checkpoints\\new_balance_16.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_16.pth\\assets\n",
      "201/201 [==============================] - 59s 295ms/step - loss: 1.2482 - accuracy: 0.5495 - val_loss: 1.5025 - val_accuracy: 0.4781 - val_f1: 0.2627\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 17: saving model to ./checkpoints\\new_balance_17.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_17.pth\\assets\n",
      "201/201 [==============================] - 58s 290ms/step - loss: 1.2418 - accuracy: 0.5509 - val_loss: 1.4915 - val_accuracy: 0.4774 - val_f1: 0.2602\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 18: saving model to ./checkpoints\\new_balance_18.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_18.pth\\assets\n",
      "201/201 [==============================] - 59s 294ms/step - loss: 1.2337 - accuracy: 0.5539 - val_loss: 1.4733 - val_accuracy: 0.4795 - val_f1: 0.2742\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 19: saving model to ./checkpoints\\new_balance_19.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_19.pth\\assets\n",
      "201/201 [==============================] - 59s 294ms/step - loss: 1.2237 - accuracy: 0.5582 - val_loss: 1.5409 - val_accuracy: 0.4808 - val_f1: 0.2835\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 20: saving model to ./checkpoints\\new_balance_20.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_20.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.2146 - accuracy: 0.5634 - val_loss: 1.5126 - val_accuracy: 0.4665 - val_f1: 0.2792\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 21: saving model to ./checkpoints\\new_balance_21.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_21.pth\\assets\n",
      "201/201 [==============================] - 58s 291ms/step - loss: 1.2082 - accuracy: 0.5658 - val_loss: 1.5114 - val_accuracy: 0.4644 - val_f1: 0.2847\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 22: saving model to ./checkpoints\\new_balance_22.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_22.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.2038 - accuracy: 0.5641 - val_loss: 1.4929 - val_accuracy: 0.4761 - val_f1: 0.2556\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 23: saving model to ./checkpoints\\new_balance_23.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_23.pth\\assets\n",
      "201/201 [==============================] - 58s 291ms/step - loss: 1.1906 - accuracy: 0.5720 - val_loss: 1.5060 - val_accuracy: 0.4665 - val_f1: 0.2831\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 24: saving model to ./checkpoints\\new_balance_24.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_24.pth\\assets\n",
      "201/201 [==============================] - 58s 291ms/step - loss: 1.1882 - accuracy: 0.5728 - val_loss: 1.4939 - val_accuracy: 0.4802 - val_f1: 0.2702\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 25: saving model to ./checkpoints\\new_balance_25.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_25.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.1814 - accuracy: 0.5758 - val_loss: 1.5220 - val_accuracy: 0.4761 - val_f1: 0.2650\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 1s 21ms/step\n",
      "\n",
      "Epoch 26: saving model to ./checkpoints\\new_balance_26.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_26.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.1727 - accuracy: 0.5775 - val_loss: 1.4934 - val_accuracy: 0.4822 - val_f1: 0.2607\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 27: saving model to ./checkpoints\\new_balance_27.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_27.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.1655 - accuracy: 0.5816 - val_loss: 1.5429 - val_accuracy: 0.4850 - val_f1: 0.2759\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 28: saving model to ./checkpoints\\new_balance_28.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_28.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.1620 - accuracy: 0.5804 - val_loss: 1.5195 - val_accuracy: 0.4850 - val_f1: 0.2713\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 29: saving model to ./checkpoints\\new_balance_29.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_29.pth\\assets\n",
      "201/201 [==============================] - 59s 293ms/step - loss: 1.1537 - accuracy: 0.5863 - val_loss: 1.5054 - val_accuracy: 0.4713 - val_f1: 0.2779\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 30: saving model to ./checkpoints\\new_balance_30.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_30.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.1505 - accuracy: 0.5866 - val_loss: 1.5254 - val_accuracy: 0.4679 - val_f1: 0.2440\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 31: saving model to ./checkpoints\\new_balance_31.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_31.pth\\assets\n",
      "201/201 [==============================] - 59s 293ms/step - loss: 1.1420 - accuracy: 0.5882 - val_loss: 1.5645 - val_accuracy: 0.4767 - val_f1: 0.2439\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 32: saving model to ./checkpoints\\new_balance_32.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_32.pth\\assets\n",
      "201/201 [==============================] - 59s 294ms/step - loss: 1.1384 - accuracy: 0.5924 - val_loss: 1.5229 - val_accuracy: 0.4870 - val_f1: 0.2894\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 33: saving model to ./checkpoints\\new_balance_33.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_33.pth\\assets\n",
      "201/201 [==============================] - 59s 296ms/step - loss: 1.1338 - accuracy: 0.5935 - val_loss: 1.5383 - val_accuracy: 0.4754 - val_f1: 0.2601\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 34: saving model to ./checkpoints\\new_balance_34.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_34.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.1310 - accuracy: 0.5966 - val_loss: 1.5221 - val_accuracy: 0.4863 - val_f1: 0.2726\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 1s 23ms/step\n",
      "\n",
      "Epoch 35: saving model to ./checkpoints\\new_balance_35.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_35.pth\\assets\n",
      "201/201 [==============================] - 59s 296ms/step - loss: 1.1212 - accuracy: 0.5972 - val_loss: 1.5195 - val_accuracy: 0.4829 - val_f1: 0.2938\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 36: saving model to ./checkpoints\\new_balance_36.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_36.pth\\assets\n",
      "201/201 [==============================] - 58s 291ms/step - loss: 1.1176 - accuracy: 0.5981 - val_loss: 1.6109 - val_accuracy: 0.4815 - val_f1: 0.2806\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 37: saving model to ./checkpoints\\new_balance_37.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_37.pth\\assets\n",
      "201/201 [==============================] - 59s 294ms/step - loss: 1.1172 - accuracy: 0.6003 - val_loss: 1.5226 - val_accuracy: 0.4897 - val_f1: 0.2800\n",
      "Epoch 38/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 38: saving model to ./checkpoints\\new_balance_38.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_38.pth\\assets\n",
      "201/201 [==============================] - 59s 293ms/step - loss: 1.1099 - accuracy: 0.6032 - val_loss: 1.5423 - val_accuracy: 0.4802 - val_f1: 0.2797\n",
      "Epoch 39/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 39: saving model to ./checkpoints\\new_balance_39.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_39.pth\\assets\n",
      "201/201 [==============================] - 58s 291ms/step - loss: 1.1079 - accuracy: 0.6032 - val_loss: 1.5553 - val_accuracy: 0.4815 - val_f1: 0.2753\n",
      "Epoch 40/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 40: saving model to ./checkpoints\\new_balance_40.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_40.pth\\assets\n",
      "201/201 [==============================] - 59s 294ms/step - loss: 1.1078 - accuracy: 0.6035 - val_loss: 1.6046 - val_accuracy: 0.4815 - val_f1: 0.2836\n",
      "Epoch 41/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 41: saving model to ./checkpoints\\new_balance_41.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_41.pth\\assets\n",
      "201/201 [==============================] - 59s 295ms/step - loss: 1.1024 - accuracy: 0.6035 - val_loss: 1.5385 - val_accuracy: 0.4808 - val_f1: 0.2830\n",
      "Epoch 42/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 42: saving model to ./checkpoints\\new_balance_42.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_42.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.0998 - accuracy: 0.6047 - val_loss: 1.5771 - val_accuracy: 0.4795 - val_f1: 0.2885\n",
      "Epoch 43/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 43: saving model to ./checkpoints\\new_balance_43.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_43.pth\\assets\n",
      "201/201 [==============================] - 59s 294ms/step - loss: 1.0919 - accuracy: 0.6112 - val_loss: 1.5982 - val_accuracy: 0.4754 - val_f1: 0.2607\n",
      "Epoch 44/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 44: saving model to ./checkpoints\\new_balance_44.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_44.pth\\assets\n",
      "201/201 [==============================] - 59s 294ms/step - loss: 1.0931 - accuracy: 0.6120 - val_loss: 1.5606 - val_accuracy: 0.4836 - val_f1: 0.2549\n",
      "Epoch 45/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 45: saving model to ./checkpoints\\new_balance_45.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_45.pth\\assets\n",
      "201/201 [==============================] - 59s 295ms/step - loss: 1.0918 - accuracy: 0.6103 - val_loss: 1.6048 - val_accuracy: 0.4726 - val_f1: 0.2851\n",
      "Epoch 46/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 46: saving model to ./checkpoints\\new_balance_46.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_46.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.0808 - accuracy: 0.6128 - val_loss: 1.5978 - val_accuracy: 0.4774 - val_f1: 0.2889\n",
      "Epoch 47/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 47: saving model to ./checkpoints\\new_balance_47.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_47.pth\\assets\n",
      "201/201 [==============================] - 59s 295ms/step - loss: 1.0801 - accuracy: 0.6155 - val_loss: 1.6465 - val_accuracy: 0.4774 - val_f1: 0.2756\n",
      "Epoch 48/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 48: saving model to ./checkpoints\\new_balance_48.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_48.pth\\assets\n",
      "201/201 [==============================] - 59s 295ms/step - loss: 1.0821 - accuracy: 0.6154 - val_loss: 1.6354 - val_accuracy: 0.4699 - val_f1: 0.2652\n",
      "Epoch 49/200\n",
      "46/46 [==============================] - 1s 23ms/step\n",
      "\n",
      "Epoch 49: saving model to ./checkpoints\\new_balance_49.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_49.pth\\assets\n",
      "201/201 [==============================] - 59s 293ms/step - loss: 1.0814 - accuracy: 0.6150 - val_loss: 1.5888 - val_accuracy: 0.4699 - val_f1: 0.2779\n",
      "Epoch 50/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 50: saving model to ./checkpoints\\new_balance_50.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_50.pth\\assets\n",
      "201/201 [==============================] - 59s 294ms/step - loss: 1.0712 - accuracy: 0.6181 - val_loss: 1.6287 - val_accuracy: 0.4761 - val_f1: 0.2740\n",
      "Epoch 51/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 51: saving model to ./checkpoints\\new_balance_51.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_51.pth\\assets\n",
      "201/201 [==============================] - 59s 295ms/step - loss: 1.0689 - accuracy: 0.6216 - val_loss: 1.6051 - val_accuracy: 0.4822 - val_f1: 0.2646\n",
      "Epoch 52/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 52: saving model to ./checkpoints\\new_balance_52.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_52.pth\\assets\n",
      "201/201 [==============================] - 59s 293ms/step - loss: 1.0672 - accuracy: 0.6215 - val_loss: 1.5922 - val_accuracy: 0.4802 - val_f1: 0.2861\n",
      "Epoch 53/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 53: saving model to ./checkpoints\\new_balance_53.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_53.pth\\assets\n",
      "201/201 [==============================] - 59s 293ms/step - loss: 1.0667 - accuracy: 0.6199 - val_loss: 1.6212 - val_accuracy: 0.4692 - val_f1: 0.2644\n",
      "Epoch 54/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 54: saving model to ./checkpoints\\new_balance_54.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_54.pth\\assets\n",
      "201/201 [==============================] - 59s 292ms/step - loss: 1.0648 - accuracy: 0.6173 - val_loss: 1.5976 - val_accuracy: 0.4685 - val_f1: 0.2657\n",
      "Epoch 55/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 55: saving model to ./checkpoints\\new_balance_55.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_55.pth\\assets\n",
      "201/201 [==============================] - 59s 294ms/step - loss: 1.0562 - accuracy: 0.6235 - val_loss: 1.6147 - val_accuracy: 0.4720 - val_f1: 0.2766\n",
      "Epoch 56/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 56: saving model to ./checkpoints\\new_balance_56.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_56.pth\\assets\n",
      "201/201 [==============================] - 59s 296ms/step - loss: 1.0537 - accuracy: 0.6248 - val_loss: 1.5860 - val_accuracy: 0.4713 - val_f1: 0.2904\n",
      "Epoch 57/200\n",
      "46/46 [==============================] - 1s 23ms/step\n",
      "\n",
      "Epoch 57: saving model to ./checkpoints\\new_balance_57.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_57.pth\\assets\n",
      "201/201 [==============================] - 62s 307ms/step - loss: 1.0644 - accuracy: 0.6184 - val_loss: 1.6592 - val_accuracy: 0.4802 - val_f1: 0.2940\n",
      "Epoch 58/200\n",
      "46/46 [==============================] - 1s 22ms/step\n",
      "\n",
      "Epoch 58: saving model to ./checkpoints\\new_balance_58.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_58.pth\\assets\n",
      "201/201 [==============================] - 60s 299ms/step - loss: 1.0549 - accuracy: 0.6243 - val_loss: 1.6239 - val_accuracy: 0.4706 - val_f1: 0.2735\n",
      "Epoch 59/200\n",
      "46/46 [==============================] - 1s 23ms/step\n",
      "\n",
      "Epoch 59: saving model to ./checkpoints\\new_balance_59.pth\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\new_balance_59.pth\\assets\n",
      "201/201 [==============================] - 59s 293ms/step - loss: 1.0516 - accuracy: 0.6252 - val_loss: 1.5879 - val_accuracy: 0.4706 - val_f1: 0.2715\n",
      "Epoch 60/200\n",
      " 23/201 [==>...........................] - ETA: 34s - loss: 1.0542 - accuracy: 0.6264"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11216\\205277368.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_sample_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_embedding_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSAMPLE_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved_model.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11216\\3136453031.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(all_sample_words, embedding_matrix, x_train, y_train, x_valid, y_valid, SAMPLE_LENGTH)\u001b[0m\n\u001b[0;32m     64\u001b[0m     model.fit(x_train, y_train, batch_size=128, epochs=200, \n\u001b[0;32m     65\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 callbacks=[Metrics(valid_data=(x_valid, y_valid)), ck_callback, tb_callback])\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[1;31m# model.fit(np.array(x_train), np.array(y_train), batch_size=128, epochs=20, validation_data=(np.array(x_valid), np.array(y_valid)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Terry\\anaconda3\\envs\\NLP_HW2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Terry\\anaconda3\\envs\\NLP_HW2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Terry\\anaconda3\\envs\\NLP_HW2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Terry\\anaconda3\\envs\\NLP_HW2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Terry\\anaconda3\\envs\\NLP_HW2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Terry\\anaconda3\\envs\\NLP_HW2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Terry\\anaconda3\\envs\\NLP_HW2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Terry\\anaconda3\\envs\\NLP_HW2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\Terry\\anaconda3\\envs\\NLP_HW2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# label_train = emotion_to_label(x_train, y_train)\n",
    "# label_val = emotion_to_label(x_valid, y_valid)\n",
    "# print(label_val[:2])\n",
    "vector_train = vectorizer(tokenized_train)\n",
    "vector_val = vectorizer(tokenized_val)\n",
    "\n",
    "\n",
    "model = train(all_sample_words, index_embedding_matrix, vector_train, label_train, vector_val, label_val, SAMPLE_LENGTH)\n",
    "model.save(\"saved_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# Continue training\n",
    "# 49 -> 63 -> 81\n",
    "model = keras.models.load_model('checkpoints/not_balance_+28.pth')\n",
    "model = train(all_sample_words, index_embedding_matrix, vector_train, label_train, vector_val, label_val, SAMPLE_LENGTH)\n",
    "model.save(\"saved_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 4s 35ms/step\n",
      "<class 'numpy.ndarray'>\n",
      "(3400,)\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Generate testing results\n",
    "# 16 63 94\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('checkpoints/balance_09.pth')\n",
    "vector_test = vectorizer(tokenized_test)\n",
    "y_prob = model.predict(np.array(vector_test))\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "print(type(y_pred))\n",
    "print(y_pred.shape)\n",
    "print(y_pred)\n",
    "index = range(len(y_pred))\n",
    "output_data = {\"index\": index, \"emotion\": y_pred}\n",
    "output_df = pd.DataFrame(output_data,)\n",
    "output_df.to_csv(\"test_prediction_aug_balance_f31_b128_raw_w_special_e09.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 91, 300)           1816500   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              439296    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,257,595\n",
      "Trainable params: 441,095\n",
      "Non-trainable params: 1,816,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('checkpoints/not_balance_20.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.06853583 0.10446616 0.04617545 0.7259581  0.0259376  0.02282379\n",
      "  0.00610308]], shape=(1, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "preds = model(vectorizer(np.array([\" why are you stupid?\"])))\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.6206019  0.04904897 0.14757547 0.17219466 0.00637367 0.00204059\n",
      "  0.00216477]], shape=(1, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "preds = model(vectorizer(np.array([\"?\"])))\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('NLP_HW2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3a6c64660b2f6c075d5cf0cb336d7bbcf3fdc21882d2f6ed91bfed2e22f0d2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
